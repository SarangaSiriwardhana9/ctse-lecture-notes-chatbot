{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd218b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from requests) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from requests) (2025.4.26)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from sentence-transformers) (4.51.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from sentence-transformers) (2.7.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from sentence-transformers) (4.13.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: PyPDF2 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (3.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: streamlit in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (1.45.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from streamlit) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from streamlit) (8.1.8)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from streamlit) (2.2.5)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from streamlit) (11.2.1)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from streamlit) (5.29.4)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from streamlit) (20.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from streamlit) (9.1.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from streamlit) (4.13.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from streamlit) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from altair<6,>=4.0->streamlit) (1.38.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\saranga\\desktop\\chatbot\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install basic packages \n",
    "%pip install requests sentence-transformers\n",
    "%pip install PyPDF2\n",
    "%pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0beea886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 documents\n",
      "Split into 18 chunks\n",
      "Loading embedding model...\n",
      "Creating embeddings for chunks...\n",
      "\n",
      "============================================================\n",
      "  CTSE Lecture Notes Chatbot\n",
      "  Type 'exit' to quit or 'new' for a new question\n",
      "============================================================\n",
      "\n",
      "Question: What's the significance of bias in a neural network, and how does it relate to the threshold value?\n",
      "--------------------------------------------------\n",
      "Answer: Bias is used to shift the output value, and it is equal to the negative of the threshold value (Bias = -Threshold value).\n",
      "\n",
      "\n",
      "Sources:\n",
      "Source 1 from ML Lec 2 - Part 1.pdf:\n",
      " Introduction to Artificial Neural Networks| Jeewaka PereraStructure of an ANN SE4010 | Current Trends in SE| Introduction to Artificial Neural Networ...\n",
      "\n",
      "Source 2 from ML Lec 2 - Part 1.pdf:\n",
      "SE4010 | Current Trends in SE| Introduction to Artificial Neural Networks| Jeewaka PereraGain an understanding of the structure and background of ANN ...\n",
      "\n",
      "Source 3 from ML Lec 2 - Part 1.pdf:\n",
      " y=ቊ0,𝑥𝑃⋅𝑤1+𝑥𝑏⋅𝑤2+𝑥𝑟⋅𝑤3<𝑡 1,𝑥𝑃⋅𝑤1+𝑥𝑏⋅𝑤2+𝑥𝑟⋅𝑤3≥𝑡 •Its easier to compute with vectors y=ቊ0,𝑥⋅𝑤<𝑡 1,𝑥⋅𝑤≥𝑡 y=ቊ0,𝑥⋅𝑤+𝑏<0 1,𝑥⋅𝑤+𝑏≥0 SE4010 | Current Trends ...\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Type your next question, 'exit' to quit, or press Enter to continue\n",
      "------------------------------------------------------------\n",
      "\n",
      "Question: What are the differences between CNNs and RNNs, and what are their applications?\n",
      "--------------------------------------------------\n",
      "Answer: CNNs (Convolutional Neural Networks) are well-suited for image and video processing tasks. They use convolutional layers to extract features from images and reduce the dimensionality of the input data. CNN applications include image classification, object detection, segmentation, text classification, and sentiment analysis. They are particularly useful for tasks where the input data has a grid-like structure.\n",
      "\n",
      "RNNs (Recurrent Neural Networks) are well-suited for sequence data, such as time-series data or natural language processing. RNNs use feedback connections to allow information to be passed from one step in the sequence to the next. RNN applications include speech recognition, machine translation, sentiment analysis, and time-series forecasting. They are particularly useful for tasks where the output at each step depends on the previous steps in the sequence.\n",
      "\n",
      "\n",
      "Sources:\n",
      "Source 1 from ML Lec 2 - Part 1.pdf:\n",
      "nguage processing tasks, such as text classification and sentiment analysis. •CNN is particularly useful for tasks where the input data has a grid -li...\n",
      "\n",
      "Source 2 from ML Lec 2 - Part 1.pdf:\n",
      "onal Neural Networks •CNN is a type of neural network that is particularly well-suited for image and video processing tasks. •CNN uses convolutional l...\n",
      "\n",
      "Source 3 from ML Lec 2 - Part 1.pdf:\n",
      "kpropagation algorithm. SE4010 | Current Trends in SE| Introduction to Artificial Neural Networks| Jeewaka PereraApplications of RNN •RNN has been use...\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Type your next question, 'exit' to quit, or press Enter to continue\n",
      "------------------------------------------------------------\n",
      "\n",
      "Question: How do quantum neural networks work?\n",
      "--------------------------------------------------\n",
      "Answer: I don't have enough information to answer this question.\n",
      "\n",
      "\n",
      "Sources:\n",
      "Source 1 from ML Lec 2 - Part 1.pdf:\n",
      "SE4010 | Current Trends in SE| Introduction to Artificial Neural Networks| Jeewaka PereraGain an understanding of the structure and background of ANN ...\n",
      "\n",
      "Source 2 from ML Lec 2 - Part 1.pdf:\n",
      " y=ቊ0,𝑥𝑃⋅𝑤1+𝑥𝑏⋅𝑤2+𝑥𝑟⋅𝑤3<𝑡 1,𝑥𝑃⋅𝑤1+𝑥𝑏⋅𝑤2+𝑥𝑟⋅𝑤3≥𝑡 •Its easier to compute with vectors y=ቊ0,𝑥⋅𝑤<𝑡 1,𝑥⋅𝑤≥𝑡 y=ቊ0,𝑥⋅𝑤+𝑏<0 1,𝑥⋅𝑤+𝑏≥0 SE4010 | Current Trends ...\n",
      "\n",
      "Source 3 from ML Lec 2 - Part 1.pdf:\n",
      "rges SE4010 | Current Trends in SE| Introduction to Artificial Neural Networks| Jeewaka Perera SE4010 | Current Trends in SE| Introduction to Artifici...\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Type your next question, 'exit' to quit, or press Enter to continue\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 188\u001b[0m\n\u001b[0;32m    185\u001b[0m model, embeddings \u001b[38;5;241m=\u001b[39m create_embeddings(chunks)\n\u001b[0;32m    187\u001b[0m \u001b[38;5;66;03m# Start interactive chat directly without sample question\u001b[39;00m\n\u001b[1;32m--> 188\u001b[0m \u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 167\u001b[0m, in \u001b[0;36mchat\u001b[1;34m(model, chunks, embeddings)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 167\u001b[0m     question \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mAsk a question: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m question\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbye\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mThank you for using the CTSE Lecture Notes Chatbot. Goodbye!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Saranga\\Desktop\\chatbot\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Saranga\\Desktop\\chatbot\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import PyPDF2\n",
    "import re\n",
    "\n",
    "# Set  API key\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBzS_RgPK9r-ZAWFndoDkm6TunuIpRRSlA\"\n",
    "\n",
    "# Step 1: Load documents from the 'data' folder - UPDATED to handle PDFs\n",
    "def load_documents(directory='./data'):\n",
    "    documents = []\n",
    "    \n",
    "    # Process text files\n",
    "    for file_path in glob.glob(f\"{directory}/*.txt\"):\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            documents.append({\n",
    "                \"content\": content,\n",
    "                \"source\": file_path\n",
    "            })\n",
    "    \n",
    "    # Process PDF files\n",
    "    for file_path in glob.glob(f\"{directory}/*.pdf\"):\n",
    "        try:\n",
    "            content = extract_text_from_pdf(file_path)\n",
    "            documents.append({\n",
    "                \"content\": content,\n",
    "                \"source\": file_path\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting text from {file_path}: {str(e)}\")\n",
    "    \n",
    "    print(f\"Loaded {len(documents)} documents\")\n",
    "    return documents\n",
    "\n",
    "# New helper function to extract text from PDFs\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            text += page.extract_text() + \"\\n\\n\"\n",
    "    \n",
    "    # Clean up the text (remove extra whitespace, etc.)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Step 2: Split documents into chunks (simple version)\n",
    "def split_into_chunks(documents, chunk_size=800, overlap=150):\n",
    "    chunks = []\n",
    "    for doc in documents:\n",
    "        content = doc[\"content\"]\n",
    "        source = doc[\"source\"]\n",
    "        \n",
    "        # Simple sliding window approach\n",
    "        for i in range(0, len(content), chunk_size - overlap):\n",
    "            chunk_text = content[i:i + chunk_size]\n",
    "            if len(chunk_text) < 100: \n",
    "                continue\n",
    "            chunks.append({\n",
    "                \"content\": chunk_text,\n",
    "                \"source\": source\n",
    "            })\n",
    "    \n",
    "    print(f\"Split into {len(chunks)} chunks\")\n",
    "    return chunks\n",
    "\n",
    "# Step 3: Create embeddings\n",
    "def create_embeddings(chunks):\n",
    "    print(\"Loading embedding model...\")\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    \n",
    "    print(\"Creating embeddings for chunks...\")\n",
    "    embeddings = []\n",
    "    for chunk in chunks:\n",
    "        embedding = model.encode(chunk[\"content\"])\n",
    "        embeddings.append(embedding)\n",
    "    \n",
    "    return model, embeddings\n",
    "\n",
    "# Step 4: Simple retrieval function\n",
    "def retrieve_relevant_chunks(query, model, chunks, embeddings, k=3):\n",
    "    # Get query embedding\n",
    "    query_embedding = model.encode(query)\n",
    "    \n",
    "    # Calculate similarity\n",
    "    similarities = cosine_similarity([query_embedding], embeddings)[0]\n",
    "    \n",
    "    # Get top k chunks\n",
    "    top_indices = np.argsort(similarities)[-k:][::-1]\n",
    "    \n",
    "    return [chunks[i] for i in top_indices]\n",
    "\n",
    "# Step 5: Function to call Google Gemini API\n",
    "def ask_gemini(prompt):\n",
    "    api_key = os.environ.get(\"GOOGLE_API_KEY\", \"\")\n",
    "    \n",
    "    url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={api_key}\"\n",
    "    \n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    data = {\n",
    "        \"contents\": [{\n",
    "            \"parts\":[{\"text\": prompt}]\n",
    "        }]\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=data)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            response_json = response.json()\n",
    "            if \"candidates\" in response_json and len(response_json[\"candidates\"]) > 0:\n",
    "                return response_json[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
    "            else:\n",
    "                return \"No valid response found in API response\"\n",
    "        else:\n",
    "            return f\"Error: {response.status_code} - {response.text}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error calling API: {str(e)}\"\n",
    "\n",
    "# Step 6: Main QA function\n",
    "def answer_question(question, model, chunks, embeddings):\n",
    "    print(f\"\\nQuestion: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Get relevant chunks\n",
    "    relevant_chunks = retrieve_relevant_chunks(question, model, chunks, embeddings)\n",
    "    \n",
    "    # Create prompt for Gemini\n",
    "    context = \"\\n\\n\".join([chunk[\"content\"] for chunk in relevant_chunks])\n",
    "    prompt = f\"\"\"Answer the following question based ONLY on the information provided in the context below.\n",
    "    If the answer is not found in the context, say \"I don't have enough information to answer this question.\"\n",
    "\n",
    "    CONTEXT:\n",
    "    {context}\n",
    "\n",
    "    QUESTION:\n",
    "    {question}\n",
    "\n",
    "    ANSWER:\"\"\"\n",
    "    \n",
    "    # Get answer from Gemini\n",
    "    answer = ask_gemini(prompt)\n",
    "    \n",
    "    print(f\"Answer: {answer}\\n\")\n",
    "    print(\"Sources:\")\n",
    "    for i, chunk in enumerate(relevant_chunks):\n",
    "        source_file = os.path.basename(chunk[\"source\"])\n",
    "        print(f\"Source {i+1} from {source_file}:\\n{chunk['content'][:150]}...\\n\")\n",
    "    \n",
    "    return answer\n",
    "\n",
    "# Step 7: Improved interactive chat interface\n",
    "def chat(model, chunks, embeddings):\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"  CTSE Lecture Notes Chatbot\")\n",
    "    print(\"  Type 'exit' to quit or 'new' for a new question\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    while True:\n",
    "        question = input(\"\\nAsk a question: \")\n",
    "        \n",
    "        if question.lower() in ['exit', 'quit', 'bye']:\n",
    "            print(\"\\nThank you for using the CTSE Lecture Notes Chatbot. Goodbye!\")\n",
    "            break\n",
    "            \n",
    "        answer = answer_question(question, model, chunks, embeddings)\n",
    "        \n",
    "        # Ask if user wants to continue\n",
    "        print(\"\\n\" + \"-\" * 60)\n",
    "        print(\"Type your next question, 'exit' to quit, or press Enter to continue\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and process documents\n",
    "    documents = load_documents()\n",
    "    chunks = split_into_chunks(documents, chunk_size=800)\n",
    "    model, embeddings = create_embeddings(chunks)\n",
    "    \n",
    "    # Start interactive chat directly without sample question\n",
    "    chat(model, chunks, embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
